{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZ6Lolss69ov",
    "outputId": "52f59cb6-315f-4017-f1f9-c66652bdf18a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20284/3450254010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPerceptron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "def print_tree(clf, X_test):\n",
    "  node_indicator = clf.decision_path(X_test)\n",
    "  leaf_id = clf.apply(X_test)\n",
    "  feature = clf.tree_.feature\n",
    "  threshold = clf.tree_.threshold\n",
    "\n",
    "  sample_id = 0\n",
    "  # obtain ids of the nodes `sample_id` goes through, i.e., row `sample_id`\n",
    "  node_index = node_indicator.indices[\n",
    "      node_indicator.indptr[sample_id] : node_indicator.indptr[sample_id + 1]\n",
    "  ]\n",
    "\n",
    "  print(\"Rules used to predict sample {id}:\\n\".format(id=sample_id))\n",
    "  for node_id in node_index:\n",
    "      # continue to the next node if it is a leaf node\n",
    "      if leaf_id[sample_id] == node_id:\n",
    "          continue\n",
    "\n",
    "      # check if value of the split feature for sample 0 is below threshold\n",
    "      if X_test[sample_id, feature[node_id]] <= threshold[node_id]:\n",
    "          threshold_sign = \"<=\"\n",
    "      else:\n",
    "          threshold_sign = \">\"\n",
    "\n",
    "      print(\n",
    "          \"decision node {node} : (X_test[{sample}, {feature}] = {value}) \"\n",
    "          \"{inequality} {threshold})\".format(\n",
    "              node=node_id,\n",
    "              sample=sample_id,\n",
    "              feature=feature[node_id],\n",
    "              value=X_test[sample_id, feature[node_id]],\n",
    "              inequality=threshold_sign,\n",
    "              threshold=threshold[node_id],\n",
    "          )\n",
    "      )\n",
    "\n",
    "import os\n",
    "    \n",
    "# File input\n",
    "def read_in_data():\n",
    "    print(os.getcwd())\n",
    "#     path = '/content/drive/My Drive/Colab Notebooks/cosmic_sleuth/data/3FHL_50.txt'\n",
    "    # path = '/content/drive/My Drive/Colab Notebooks/cosmic_sleuth/data/four_sources_plus_background.txt'\n",
    "    # path = '/content/drive/My Drive/Colab Notebooks/cosmic_sleuth/data/sources_ft_numberlabels.txt'\n",
    "\n",
    "#     drive.mount('/content/drive')\n",
    "    with open(path, 'r') as f:\n",
    "      temp = np.genfromtxt(f,delimiter=' ', dtype= None)\n",
    "\n",
    "    #label_size = 3\n",
    "    # label_size = 1\n",
    "    \n",
    "    X = np.array([[a, b, c, d, e, f] for (a, b, c, d, e, f, g) in temp])\n",
    "    y = np.array([g for (a, b, c, d, e, f, g) in temp])\n",
    "    # X = temp[:, :-1]\n",
    "    # y = temp[:, -1]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Find all unique x,y,x coordinates, assign them a label\n",
    "def enumerate_unique_labels(y):\n",
    "    y_options = np.unique(y, axis=0)\n",
    "    # Convert x,y,z coordinate into an enumerated label\n",
    "    print(y_options)\n",
    "    print(np.linalg.norm(y_options[0]))\n",
    "    print(np.linalg.norm(y_options[1]))\n",
    "    print(np.linalg.norm(y_options[2]))\n",
    "    print(np.linalg.norm(y_options[3]))\n",
    "    y_labels = np.array([np.where(y_options == yi)[0][0] for yi in y])\n",
    "    return y_labels\n",
    "\n",
    "def eval_classifier(clf, X_train, X_test, y_train, y_test):\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "\n",
    "    print('\\t', clf.score(X_train, y_train), end=\"\\t\")\n",
    "    print(clf.score(X_test, y_test))\n",
    "\n",
    "    return clf\n",
    "\n",
    "def mlp():\n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = 6, activation='relu'))\n",
    "    model.add(Dense(25, activation='relu'))\n",
    "    model.add(Dense(50, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def eval_mlp(model, X_train, X_test, y_train, y_test):\n",
    "    # Convert target classes to categorical ones\n",
    "    Y_train = to_categorical(y_train)\n",
    "    Y_test = to_categorical(y_test)\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=200, batch_size=45, verbose=1)\n",
    "    # Test the model after training\n",
    "    test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print(f'Mulilayer Perceptron results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
    "    \n",
    "def eval_Linregression(X_train, X_test, y_train, y_test):\n",
    "    possibleys = [0, 1, 2, 3]\n",
    "    clf = LinearRegression().fit(X_train, y_train)\n",
    "    yhat = clf.predict(X_test)\n",
    "    yclass = yhat\n",
    "    for i in range(yhat.shape[0]): \n",
    "      yclass[i] = np.argmin(np.linalg.norm(possibleys - yhat[i]))\n",
    "    score = sum([y1 == y2 for (y1, y2) in zip(yclass, y_test)])\n",
    "    score = 1.0 * score / y_test.shape[0]\n",
    "\n",
    "    print('\\tLinearRegression Score\\t ', score)\n",
    "    return clf\n",
    "\n",
    "def main():\n",
    "    X, y = read_in_data()\n",
    "    # y_labels = enumerate_unique_labels(y)\n",
    "    # print(np.unique(y_labels))\n",
    "    y_options = np.unique(y, axis=0)\n",
    "    y_labels = np.array([np.where(y_options == yi)[0][0] for yi in y])\n",
    "    print(y_labels)\n",
    "\n",
    "    U, S, Vh = np.linalg.svd(X - X.mean(axis=0))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(U[:, :6], y_labels, test_size=0.2)\n",
    "\n",
    "    # Evaluate many different classifiers\n",
    "    print('Decision Tree:  ', end='\\t')\n",
    "    clf = eval_classifier(DecisionTreeClassifier(), X_train, X_test, y_train, y_test)\n",
    "    plt.figure(figsize=(20,20))  # set plot size (denoted in inches)\n",
    "    # tree.plot_tree(clf, fontsize=10)\n",
    "    # plt.show()\n",
    "\n",
    "    print('Random Forest:', end='\\t')\n",
    "    eval_classifier(RandomForestClassifier(n_estimators=1000), X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print('LightGBM:', end='\\t')\n",
    "    eval_classifier(LGBMClassifier(objective='multiclass'), X_train, X_test, y_train, y_test)\n",
    "\n",
    "    print('1-NN Classifier:', end='\\t')\n",
    "    eval_classifier(KNeighborsClassifier(n_neighbors=1), X_train, X_test, y_train, y_test)\n",
    "    print('3-NN Classifier:', end='\\t')\n",
    "    eval_classifier(KNeighborsClassifier(n_neighbors=3), X_train, X_test, y_train, y_test)\n",
    "    print('10-NN Classifier:', end='\\t') \n",
    "    eval_classifier(KNeighborsClassifier(n_neighbors=10), X_train, X_test, y_train, y_test)\n",
    "    print('GaussianNB Class.:', end='\\t')\n",
    "    eval_classifier(GaussianNB(), X_train, X_test, y_train, y_test)\n",
    "    # print('LinearRegression:', end='\\t')\n",
    "    # eval_classifier(LinearRegression(), X_train, X_test, y_train, y_test)\n",
    "    # print('LinearRegression:', end='\\t')\n",
    "    # eval_Linregression(X_train, X_test, y_train, y_test)\n",
    "    # print('LogisticRegression:', end='\\t')\n",
    "    # eval_classifier(LogisticRegression(), X_train, X_test, y_train, y_test)\n",
    "    # print('Perceptron Class.:', end='\\t')\n",
    "    # eval_classifier(Perceptron(), X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # model = mlp()\n",
    "    # print(model.summary())\n",
    "    # print(X_train.shape)\n",
    "\n",
    "    # eval_mlp(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYMpp_HeufvT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
